"""
QUICK START GUIDE
"""

# =============================================================================
# 1. CHU·∫®N B·ªä M√îI TR∆Ø·ªúNG
# =============================================================================

# C√†i ƒë·∫∑t dependencies
pip install -r requirements.txt

# Verify installation
python -c "import torch; import chess; import pygame; print('‚úÖ All dependencies installed')"


# =============================================================================
# 2. TRAIN MODEL L·∫¶N ƒê·∫¶U
# =============================================================================

# T√πy ch·ªçn A: Full pipeline (self-play + training)
python main.py train --output-dir ./models

# T√πy ch·ªçn B: Ch·ªâ t·∫°o self-play data
python main.py selfplay --num-games 20 --white-mode random --black-mode random --save-data data.npz


# =============================================================================
# 3. CH∆†I GAME V·ªöI AI
# =============================================================================

# A. Ch∆°i v·ªõi Tr·∫Øng (b·∫°n ƒëi tr∆∞·ªõc)
python main.py play --player-color white --depth 3

# B. Ch∆°i v·ªõi ƒêen (AI ƒëi tr∆∞·ªõc)
python main.py play --player-color black --depth 4

# ƒêi·ªÅu khi·ªÉn:
#   - Click chu·ªôt tr√°i: Ch·ªçn qu√¢n
#   - K√©o ƒë·∫øn √¥ kh√°c: Di chuy·ªÉn
#   - Click ph·∫£i: Undo
#   - R: Reset game
#   - Q: Quit


# =============================================================================
# 4. PH√ÇN T√çCH V·ªä TR·ªä
# =============================================================================

# Analyze v·ªã tr√≠ m·ªü ƒë·∫ßu
python main.py analyze --depth 3

# Analyze v·ªã tr√≠ custom (FEN format)
python main.py analyze --depth 4 --fen "r1bqkb1r/pppp1ppp/2n2n2/1B2p3/4P3/5N2/PPPP1PPP/RNBQK2R w KQkq - 0 1"


# =============================================================================
# 5. GENERATE M·ªåI DATA
# =============================================================================

# Minimax vs Random (ƒë·ªÉ train NN h·ªçc t·ª´ minimax)
python main.py selfplay --num-games 50 --white-mode minimax --black-mode random --depth 3 --save-data minimax_vs_random.npz

# Minimax vs Minimax (data t·ªët nh·∫•t)
python main.py selfplay --num-games 100 --white-mode minimax --black-mode minimax --depth 3 --save-data minimax_vs_minimax.npz


# =============================================================================
# 6. ADVANCED USAGE
# =============================================================================

# Thay ƒë·ªïi ƒë·ªô s√¢u Minimax (l·ªõn = m·∫°nh h∆°n nh∆∞ng ch·∫≠m h∆°n)
python main.py play --depth 1    # Nhanh, y·∫øu
python main.py play --depth 3    # C√¢n b·∫±ng
python main.py play --depth 5    # M·∫°nh, ch·∫≠m

# S·ª≠ d·ª•ng GPU (n·∫øu c√≥)
# (Code t·ª± ƒë·ªông detect GPU, kh√¥ng c·∫ßn config)


# =============================================================================
# 7. WORKFLOW TRAINING LOOP
# =============================================================================

# Step 1: T·∫°o training data
python main.py selfplay --num-games 50 --white-mode random --black-mode random --save-data initial_data.npz

# Step 2: Train model ƒë·∫ßu ti√™n
python main.py train

# Step 3: Play m·ªôt v√†i game ƒë·ªÉ c·∫£m nh·∫≠n
python main.py play --depth 2

# Step 4: Generate more quality data b·∫±ng trained model
python main.py selfplay --num-games 100 --white-mode minimax --black-mode minimax --depth 3 --save-data improved_data.npz

# Step 5: Re-train model v·ªõi d·ªØ li·ªáu t·ªët h∆°n
python main.py train

# Repeat 3-5 ƒë·ªÉ ti·∫øp t·ª•c improve


# =============================================================================
# 8. DEBUG & TESTING
# =============================================================================

# Test board state representation
python -c "
from board_state import BoardState
import chess
board = chess.Board()
tensor = BoardState.board_to_tensor(board)
print(f'Tensor shape: {tensor.shape}')
print(f'White pawns plane: {tensor[0]}')
"

# Test neural network
python -c "
from value_network import ValueNetwork
import numpy as np
network = ValueNetwork()
dummy_board = np.random.randn(12, 8, 8).astype(np.float32)
value = network.evaluate_position(dummy_board)
print(f'Position value: {value:.4f}')
"

# Test minimax engine
python -c "
from minimax_engine import MinimaxEngine
from value_network import ValueNetwork
import chess
network = ValueNetwork()
engine = MinimaxEngine(network, max_depth=2)
board = chess.Board()
move = engine.get_best_move(board)
print(f'Best move: {move}')
"

# Test self-play
python -c "
from self_play import SelfPlayManager
manager = SelfPlayManager()
stats = manager.play_games(num_games=5, white_mode='random', black_mode='random')
print(stats)
"


# =============================================================================
# 9. FILE STRUCTURE
# =============================================================================

project1/
‚îú‚îÄ‚îÄ board_state.py          # Bi·ªÉu di·ªÖn state (12x8x8)
‚îú‚îÄ‚îÄ value_network.py        # Neural Network
‚îú‚îÄ‚îÄ minimax_engine.py       # Minimax + Alpha-Beta
‚îú‚îÄ‚îÄ self_play.py            # Self-play generator
‚îú‚îÄ‚îÄ train.py                # Training loop
‚îú‚îÄ‚îÄ gui.py                  # Pygame GUI
‚îú‚îÄ‚îÄ main.py                 # Entry point
‚îú‚îÄ‚îÄ requirements.txt        # Dependencies
‚îú‚îÄ‚îÄ README.md               # Documentation
‚îú‚îÄ‚îÄ QUICKSTART.md           # File n√†y
‚îî‚îÄ‚îÄ models/                 # Output directory
    ‚îú‚îÄ‚îÄ chess_value_network.pth
    ‚îú‚îÄ‚îÄ best_model.pth
    ‚îú‚îÄ‚îÄ training_loss.png
    ‚îî‚îÄ‚îÄ training_data.npz


# =============================================================================
# 10. TROUBLESHOOTING
# =============================================================================

# L·ªói: "ModuleNotFoundError: No module named 'chess'"
# Gi·∫£i ph√°p: pip install python-chess

# L·ªói: "No module named 'pygame'"
# Gi·∫£i ph√°p: pip install pygame

# L·ªói: "CUDA out of memory"
# Gi·∫£i ph√°p: Gi·∫£m batch size trong train.py ho·∫∑c d√πng CPU

# L·ªói: "AI move qu√° ch·∫≠m"
# Gi·∫£i ph√°p: Gi·∫£m depth (--depth 2 thay v√¨ 4)

# L·ªói: "pygame window kh√¥ng m·ªü"
# Gi·∫£i ph√°p: ƒê·∫£m b·∫£o X11 display ho·∫∑c s·ª≠ d·ª•ng headless mode


# =============================================================================
# 11. TIPS & TRICKS
# =============================================================================

# Xem game history
python -c "
import chess
board = chess.Board()
print('Move history:', board.move_stack)
"

# Export game to PGN
with open('game.pgn', 'w') as f:
    f.write(str(game))

# Calculate eval from FEN
python main.py analyze --fen 'r1bqkb1r/pppppppp/2n2n2/8/8/5N2/PPPPPPPP/RNBQKB1R w KQkq - 0 1'

# Batch training data
python main.py selfplay --num-games 1000 --white-mode minimax --black-mode minimax --depth 3 --save-data large_dataset.npz


# =============================================================================
# 12. PERFORMANCE NOTES
# =============================================================================

Depth   Speed       Quality     Recommended for
1       Very Fast   Weak        Testing
2       Fast        Decent      Casual play
3       Medium      Good        Balanced (default)
4       Slow        Strong      Serious play
5+      Very Slow   Very Strong  Analysis only

GPU acceleration: ~3-5x faster than CPU
Alpha-Beta: ~10-100x speedup vs pure minimax


# =============================================================================
# DONE! üéâ
# =============================================================================

"""

# ·ª®ng d·ª•ng AI Chess c·ªßa b·∫°n ƒë√£ s·∫µn s√†ng!
# B∆∞·ªõc ti·∫øp theo: python main.py train
